{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyttRPS/DataAnalysisInMusic/blob/main/DataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muYKU07tmSkd"
      },
      "source": [
        "# Speech Emotion Recognition\n",
        "In order to import our data set to colaboratory, we need to run a set of commands to install kaggle, make a directory, copy the API .json file, give permissions, download the data set and finally unzip it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjAeU_z8qhn4"
      },
      "source": [
        "! pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao9OVYSxdJum"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQxyG1zUd2_p"
      },
      "source": [
        "! mkdir ~/.kaggle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_M09EFd6bq"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17WOWoutd9l7"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9whCVLAeSul"
      },
      "source": [
        "! kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRdb7NSnf71g"
      },
      "source": [
        "! unzip /content/ravdess-emotional-speech-audio.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJbySiq1rF6E"
      },
      "source": [
        "! pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Y16MU7nVWB"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2d2zTvPnpaQ"
      },
      "source": [
        "# Libraries used for Data Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Libraries used to navigate, manipulate and use data in the operating file system\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Librosa lets us use Python for extracting and analysing data from audio files\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Seaborn and matplotlib are libraries used for plotting data into informative graphs\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn is a library used to perform machine learning processes \n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# IPython is a Jupyter based library which we use to display audio objects in the notebook\n",
        "from IPython.display import Audio\n",
        "\n",
        "# TensorFlow is the platform that opens possibilites for end-to-end machine learning, Keras is the framework used \n",
        "from tensorflow import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Mjhwh-vnkR"
      },
      "source": [
        "# RAVDESS Dataset\n",
        "The employed dataset is the RAVDESS dataset provided on [Kaggle](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio).\n",
        "\n",
        "The documentation provides information about the files, their naming convention, sample size and type. 1440 files, 24 actors vocalizing two lexically matched statements in neutral North American Accent.\n",
        "\n",
        "The filenames are unique to a set of identifiers that are given a numerical value corresponding to the following documentation:\n",
        "\n",
        "*   Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "*   Vocal channel (01 = speech, 02 = song).\n",
        "*   Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "*   Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "*   Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "*   Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "*   Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "*Example file: 03-01-08-01-01-02-11.wav*\n",
        "\n",
        "1.   Audio-only (03)\n",
        "2.   Speech (01)\n",
        "3.   Surprised (08)\n",
        "4.   Normal (01)\n",
        "5.   Statement \"Kids\" (01)\n",
        "6.   2nd Repetition (02)\n",
        "7.   Actor 11 (11)\n",
        "     Male, as the ID is odd.\n",
        "\n",
        "**How to cite the RAVDESS**\n",
        "\n",
        "*Academic citation*\n",
        "\n",
        "If you use the RAVDESS in an academic publication, please use the following citation: \n",
        "Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391."
      ]
    }
  ]
}